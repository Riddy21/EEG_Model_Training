{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31e02df7",
   "metadata": {},
   "source": [
    "# Testing Notebook\n",
    "\n",
    "This notebook is to input a model from training and test on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad02c89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Data management\n",
    "import pandas as pd\n",
    "\n",
    "# Data processing\n",
    "from ssqueezepy import ssq_cwt\n",
    "\n",
    "# Model training\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, TimeDistributed\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, BatchNormalization\n",
    "from tensorflow.keras.layers import LSTM, GRU\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f2da8b",
   "metadata": {},
   "source": [
    "## Test Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf917f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read test EEG data from dat directory\n",
    "test_file = pd.read_csv('t1_a6_dataset/GO/dk1_test_1673473168.csv', header=None)\n",
    "test_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b26778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try test file\n",
    "\n",
    "# Convert to numpy arrays\n",
    "timestamps, tp9, af7, af8, tp10 = test_file.T.to_numpy()\n",
    "\n",
    "# Get the frequency of the samples \n",
    "start = datetime.strptime(str(timestamps[0]), \"%Y-%m-%d %H:%M:%S.%f\")\n",
    "end = datetime.strptime(str(timestamps[-1]), \"%Y-%m-%d %H:%M:%S.%f\")\n",
    "duration = (end-start).total_seconds()\n",
    "fs = timestamps.size/duration\n",
    "\n",
    "Twtp9, Wtp9, *_ = ssq_cwt(tp9, fs=fs)\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "fig.add_subplot(3, 1, 2)\n",
    "plt.imshow(np.abs(Twtp9), aspect='auto', cmap='turbo')\n",
    "fig.add_subplot(3, 1, 1)\n",
    "plt.imshow(np.abs(Wtp9), aspect='auto', cmap='turbo')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74e6f6a",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "280d63a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "6\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# Pull all file data\n",
    "files = defaultdict(list)\n",
    "\n",
    "# Number of files per category to pull\n",
    "num_files = len(min((glob.glob('./t1_compatability_dataset/GO/dk*.csv'),\n",
    "                     glob.glob('./t1_compatability_dataset/STOP/dk*.csv'),\n",
    "                     glob.glob('./t1_compatability_dataset/REST/dk*.csv')),\n",
    "                key=len))\n",
    "\n",
    "for i, file in enumerate(glob.glob('./test_dataset/GO/ridvan2*.csv')):\n",
    "#     if i == num_files:\n",
    "#         break\n",
    "    files[\"GO\"].append(pd.read_csv(file, header=None))\n",
    "    \n",
    "for i, file in enumerate(glob.glob('./test_dataset/REST/ridvan2*.csv')):\n",
    "#     if i == num_files:\n",
    "#         break\n",
    "    files[\"REST\"].append(pd.read_csv(file, header=None))\n",
    "    \n",
    "for i, file in enumerate(glob.glob('./test_dataset/STOP/ridvan2*.csv')):\n",
    "#     if i == num_files:\n",
    "#         break\n",
    "    files[\"STOP\"].append(pd.read_csv(file, header=None))\n",
    "    \n",
    "print(len(files['GO']))\n",
    "print(len(files['STOP']))\n",
    "print(len(files['REST']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb608ff0",
   "metadata": {},
   "source": [
    "## Signal Squeeze Wavelet Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07ddf7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_to_ssq(timeseries):\n",
    "    \"\"\"\n",
    "    Converts 4 channel time series data to ssq wavelet transform\n",
    "    \"\"\"\n",
    "    timestamps, tp9, af7, af8, tp10 = timeseries\n",
    "    \n",
    "    # Get the frequency of the samples \n",
    "    start = datetime.strptime(str(timestamps[0]), \"%Y-%m-%d %H:%M:%S.%f\")\n",
    "    end = datetime.strptime(str(timestamps[-1]), \"%Y-%m-%d %H:%M:%S.%f\")\n",
    "    duration = (end-start).total_seconds()\n",
    "    fs = timestamps.size/duration\n",
    "    \n",
    "    Twtp9, _, *_ = ssq_cwt(tp9, fs=fs)\n",
    "    Twtp10, _, *_ = ssq_cwt(tp10, fs=fs)\n",
    "    Twaf7, _, *_ = ssq_cwt(af7, fs=fs)\n",
    "    Twaf8, _, *_ = ssq_cwt(af8, fs=fs)\n",
    "    \n",
    "    return np.array((Twtp9, Twaf7, Twaf8, Twtp10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4b7c8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 files left to convert\n"
     ]
    }
   ],
   "source": [
    "# Compile all files into test data\n",
    "X = []\n",
    "t = []\n",
    "\n",
    "key_dict = {\"STOP\":(0.0, 0.0, 1.0),\n",
    "            \"GO\":(0.0, 1.0, 0.0),\n",
    "            \"REST\": (1.0, 0.0, 0.0)}\n",
    "\n",
    "original_sample_size = 3000\n",
    "buffer_sample_size = 500\n",
    "training_sample_size = 25\n",
    "\n",
    "num_files = sum([len(x) for x in files.values()])\n",
    "                \n",
    "for key, data in files.items():\n",
    "    for recording in data:\n",
    "        if not num_files%10:\n",
    "            print(\"%d files left to convert\" % num_files)\n",
    "        num_files -= 1\n",
    "        \n",
    "        # if file is smaller than 3000 samples, don't use it\n",
    "        if len(recording[0]) < original_sample_size:\n",
    "            continue\n",
    "\n",
    "        # Split file into buffer size samples\n",
    "        time_samples = np.split(recording.head(original_sample_size).T.to_numpy(),\n",
    "                                     int(original_sample_size/buffer_sample_size), axis=1)\n",
    "        \n",
    "        for time_sample in time_samples:\n",
    "            # Convert to numpy arrays\n",
    "            ssq_data = ts_to_ssq(time_sample)\n",
    "\n",
    "            # Take the magnitude of the wavelet transform only\n",
    "            ssq_data = np.abs(ssq_data)\n",
    "\n",
    "            # Must transpose data to (frame, height, channel) for training\n",
    "            ssq_data = ssq_data.transpose(2,1,0)\n",
    "\n",
    "            # Split sample into many blocks\n",
    "            wavelet_samples = np.split(ssq_data, int(buffer_sample_size/training_sample_size))\n",
    "\n",
    "            X.extend(wavelet_samples)\n",
    "            t.extend([key_dict[key] for i in range(len(wavelet_samples))])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "214a6150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2280 (25, 229, 4)\n",
      "2280 (0.0, 1.0, 0.0)\n"
     ]
    }
   ],
   "source": [
    "print(len(X), X[0].shape)\n",
    "print(len(t), t[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7071398",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1\n",
    "X, t = shuffle(np.array(X), np.array(t), random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70f5118",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98b363a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-02 20:25:25.249914: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2023-02-02 20:25:25.329921: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:21:00.0 name: Tesla K20Xm computeCapability: 3.5\n",
      "coreClock: 0.732GHz coreCount: 14 deviceMemorySize: 5.57GiB deviceMemoryBandwidth: 232.46GiB/s\n",
      "2023-02-02 20:25:25.330384: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-02-02 20:25:25.333243: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2023-02-02 20:25:25.335163: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2023-02-02 20:25:25.335641: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2023-02-02 20:25:25.338549: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-02-02 20:25:25.339814: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-02-02 20:25:25.345598: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-02-02 20:25:25.347050: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
      "2023-02-02 20:25:25.360549: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2294460000 Hz\n",
      "2023-02-02 20:25:25.361729: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f15a0000b60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2023-02-02 20:25:25.361756: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2023-02-02 20:25:25.509581: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5be8fa0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-02-02 20:25:25.509637: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K20Xm, Compute Capability 3.5\n",
      "2023-02-02 20:25:25.510859: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:21:00.0 name: Tesla K20Xm computeCapability: 3.5\n",
      "coreClock: 0.732GHz coreCount: 14 deviceMemorySize: 5.57GiB deviceMemoryBandwidth: 232.46GiB/s\n",
      "2023-02-02 20:25:25.510966: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-02-02 20:25:25.511022: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2023-02-02 20:25:25.511074: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2023-02-02 20:25:25.511125: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2023-02-02 20:25:25.511177: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-02-02 20:25:25.511228: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-02-02 20:25:25.511282: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-02-02 20:25:25.512971: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
      "2023-02-02 20:25:25.513064: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-02-02 20:25:25.514150: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-02-02 20:25:25.514178: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \n",
      "2023-02-02 20:25:25.514192: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \n",
      "2023-02-02 20:25:25.516073: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5300 MB memory) -> physical GPU (device: 0, name: Tesla K20Xm, pci bus id: 0000:21:00.0, compute capability: 3.5)\n",
      "Layer gru_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('models/trial1/attempt8_500.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea4d2811",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-02 20:25:31.362521: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2023-02-02 20:25:31.559959: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2280/2280 [==============================] - 42s 18ms/step - loss: 6.3017 - accuracy: 0.4167\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X, t, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ce7cac46",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
